{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b680acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import matplotlib.image as image\n",
    "from PIL import Image, ImageOps\n",
    "from numpy import asarray\n",
    "import threading\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense,Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "096ed77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)#Color conversion BGR 2 RGB\n",
    "    image.flags.writeable = False #Image is unwriteable\n",
    "    results = model.process(image)#Make prediction\n",
    "    image.flags.writeable = True#Image is now writeable\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)#color conversion RGB 2 BGR\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c51cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS)#Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS)#Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)#Draw hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)#Draw hand connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38bac019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModel():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, activation='tanh', input_shape=(30,1662)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(128, return_sequences=True, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(64, return_sequences=False, activation='tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    #model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "    model.add(Dense(actions.shape[0], activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "    model.load_weights('finalModel60fpsfinal12.h5')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4b1d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    #Draw face connections\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS,\n",
    "                             mp_drawing.DrawingSpec(color=(80, 110, 10), thickness = 1, circle_radius =1),\n",
    "                             mp_drawing.DrawingSpec(color=(80, 256, 121), thickness = 1, circle_radius =1)\n",
    "                             )\n",
    "    #Draw pose connections\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(80, 22, 10), thickness = 2, circle_radius =4),\n",
    "                             mp_drawing.DrawingSpec(color=(80, 44, 121), thickness = 2, circle_radius =2)\n",
    "                             )\n",
    "    #Draw hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121, 22, 76), thickness = 2, circle_radius =4),\n",
    "                             mp_drawing.DrawingSpec(color=(121, 44, 250), thickness = 2, circle_radius =2)\n",
    "                             )\n",
    "    #Draw hand connections\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245, 117, 66), thickness = 2, circle_radius =4),\n",
    "                             mp_drawing.DrawingSpec(color=(245, 66, 230), thickness = 2, circle_radius =2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "016bfead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if \\\n",
    "        results.face_landmarks else np.zeros(468*3)\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if \\\n",
    "        results.pose_landmarks else np.zeros(33*4)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if \\\n",
    "        results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if \\\n",
    "        results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([pose, face, lh, rh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cd88021",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [(0, 215, 255), (192,192,192), (50,127,205), (142, 241, 53), (123, 123 ,133), (214, 122, 141),(214, 122, 141),(214, 122, 141),\n",
    "          (214, 122, 141),(214, 122, 141),(214, 122, 141),(214, 122, 141),(214, 122, 141),(214, 122, 141),(214, 122, 141),(214, 122, 141),\n",
    "         (245,117,16), (117,245,16), (16,117,245), (142, 241, 53), (123, 123 ,133), (214, 122, 141),(245,117,16), (117,245,16), (16,117,245), (142, 241, 53), (123, 123 ,133), (214, 122, 141),\n",
    "         (245,117,16), (117,245,16), (16,117,245), (142, 241, 53), (123, 123 ,133), (214, 122, 141),(245,117,16), (117,245,16), (16,117,245), (142, 241, 53), (123, 123 ,133), (214, 122, 141)]\n",
    "def prob_viz(res, actions, input_frame, colors):\n",
    "    output_frame = input_frame.copy()\n",
    "    count = 0\n",
    "    res_arr = np.array(res)\n",
    "    idx = np.argsort(res_arr) \n",
    "    idx = idx[::-1]\n",
    "    res_arr = res_arr[idx]\n",
    "    new_actions = actions[idx]\n",
    "#     for num, prob in enumerate(res):\n",
    "#         cv2.rectangle(output_frame, (0,60+num*20), (int(prob*100), 90+num*20), colors[num], -1)\n",
    "#         cv2.putText(output_frame, actions[num].split('_')[0], (0, 85+num*20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "#         cv2.putText(output_frame, str(int(prob*100)), (150, 85+num*20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.putText(output_frame, 'Action', (0, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(output_frame, 'Percentage', (100, 65), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    for num, prob in enumerate(sorted(res, reverse= True)):\n",
    "        count += 1\n",
    "        cv2.rectangle(output_frame, (0,70+num*20), (int(prob*100), 90+num*20), colors[num], -1)\n",
    "        cv2.putText(output_frame, new_actions[num].split('_')[0], (0, 85+num*20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(output_frame, str(\"{:.2f}\".format(prob*100))+' %', (110, 85+num*20), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2, cv2.LINE_AA)\n",
    "        if count == 3:\n",
    "            break\n",
    "       \n",
    "    return output_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4c5f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gg(model):\n",
    "    # 1. New detection variables\n",
    "    sequence = []\n",
    "    sentence = ['']\n",
    "    threshold = 0.75\n",
    "    predictions = []\n",
    "    no_of_frame = 0\n",
    "    a = 0\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    # Set mediapipe model \n",
    "    start_time = time.time()\n",
    "    with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "        while cap.isOpened():\n",
    "\n",
    "            # Read feed\n",
    "            ret, frame = cap.read()\n",
    "            no_of_frame += 1\n",
    "            # Make detections\n",
    "            image, results = mediapipe_detection(frame, holistic)\n",
    "            print(results)\n",
    "\n",
    "            # Draw landmarks\n",
    "            draw_styled_landmarks(image, results)\n",
    "\n",
    "            # 2. Prediction logic\n",
    "            keypoints = extract_keypoints(results)\n",
    "    #         sequence.insert(0,keypoints)\n",
    "    #         sequence = sequence[:30]\n",
    "            sequence.append(keypoints)\n",
    "            sequence = sequence[-30:]\n",
    "\n",
    "            if len(sequence) == 30:\n",
    "                res = model.predict(np.expand_dims(sequence, axis=0))[0]\n",
    "                print(actions[np.argmax(res)])\n",
    "                predictions.append(np.argmax(res))\n",
    "\n",
    "            #3. Viz logic\n",
    "                if np.unique(predictions[-15:])[0]==np.argmax(res): \n",
    "                    if res[np.argmax(res)] > threshold: \n",
    "                        #if len(sentence) > 0: \n",
    "                            if actions[np.argmax(res)].split('_')[0] != sentence[-1]: \n",
    "                                if actions[np.argmax(res)].split('_')[0] == 'Wait' and sentence[-1]!='':#actions[0].split('_')[0]\n",
    "                                    sentence.append('') #actions[np.argmax(res)].split('_')[0]\n",
    "                                #elif sentence[-1] == ' ':#actions[0].split('_')[0]\n",
    "                                elif actions[np.argmax(res)].split('_')[0] != 'Wait' and sentence[-1]=='':\n",
    "                                    sentence.append(actions[np.argmax(res)].split('_')[0])\n",
    "    #                             elif np.unique(predictions[-90:])[0] == np.argmax(res) and a > 4 and actions[np.argmax(res)].split('_')[0] != 'wait':\n",
    "    #                                 sentence.append(actions[np.argmax(res)].split('_')[0])\n",
    "\n",
    "                       # else:\n",
    "                           # sentence.append(actions[np.argmax(res)].split('_')[0])\n",
    "\n",
    "                if len(sentence) > 7: \n",
    "                    sentence = ['']\n",
    "\n",
    "                # Viz probabilities\n",
    "                image = prob_viz(res, actions, image, colors)\n",
    "\n",
    "            #cv2.putText(image, \"{}\".format(no_of_frame), (600, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "            cv2.rectangle(image, (0,0), (640, 40), (129, 196, 26), -1)\n",
    "            cv2.putText(image, ' '.join(sentence), (3,30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            if no_of_frame == 30:\n",
    "                no_of_frame = 0\n",
    "                a += 1\n",
    "            # Show to screen\n",
    "            image = cv2.resize(image,(960,720))\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "            # Break gracefully\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "    end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a70d98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haha():\n",
    "    window2=Tk()\n",
    "    window2.title(\" DanChuBe's Members \")\n",
    "    window2.geometry(\"980x720\")\n",
    "    newlabel = Label(window2,text = \"Tạ Đình Sơn Tùng \",font=('HERSHEY SIMPLEX',20)).place(x=100,y=50)\n",
    "    newlabel = Label(window2,text = \"Tạ Đình Sơn Tùng \",font=('HERSHEY SIMPLEX',20)).place(x=600,y=50)\n",
    "    newlabel = Label(window2,text = \"Tạ Đình Sơn Tùng \",font=('HERSHEY SIMPLEX',20)).place(x=100,y=350)\n",
    "    newlabel = Label(window2,text = \"Tạ Đình Sơn Tùng \",font=('HERSHEY SIMPLEX',20)).place(x=600,y=350)\n",
    "    window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74c24aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseProject():\n",
    "    window2=Tk()\n",
    "    window2.title(\" Choose Project \")\n",
    "    window2.geometry(\"600x300\")\n",
    "    button1 = Button(window2,text = \"Sign Language Recognition\",command=SignLanguageRecognition).place(x = 120,y = 150)\n",
    "    button2 = Button(window2,text = \"Image compression using PCA\").place(x = 410,y = 150)\n",
    "    window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ebd2a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SignLanguageRecognition():\n",
    "    model=getModel()\n",
    "    gg(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6b59d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic #Holistic model\n",
    "mp_drawing = mp.solutions.drawing_utils #Drawing utilities\n",
    "actions = np.array(['Walk_', 'Wait_', 'Hello_L','Hello_R','Name_','No_','Sorry_R','Thanks_L',\n",
    "                    'Fire_','Give up_','House_','Ready_','Drink_','Sleep_','Where_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b8e863c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "window=Tk()\n",
    "window.title(\" Project Team DanChuBe \")\n",
    "window.geometry(\"600x300\")\n",
    "newlabel = Label(text = \" ĐẤN CHÚ BÈ \",font=('HERSHEY SIMPLEX',20),fg='red').place(x=205,y=50)\n",
    "newlabel2 = Label(text = \" AI1605 \",font=('HERSHEY SIMPLEX',15),fg='red').place(x=260,y=95)\n",
    "button1 = Button(text = \"Projects\",font=10,bg='yellow',width=15,height=2,command=chooseProject,fg='green',activebackground='yellow').place(x = 60,y = 150)\n",
    "button2 = Button(text = \"Members\",font=10,width=15,height=2,command=haha,fg='blue',bg='yellow').place(x = 350,y = 150)\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aca609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
